{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stanza\n",
    "# !pip install ollama\n",
    "# !pip install vertexai\n",
    "# !pip install -t lib google-auth google-auth-httplib2 google-api-python-client --upgrade\n",
    "# !pip install pandas_gbq\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/pm/44lz1vt16w53yrztk3stvdc40000gn/T/ipykernel_12780/764314575.py\", line 4, in <module>\n",
      "    import stanza\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/stanza/__init__.py\", line 1, in <module>\n",
      "    from stanza.pipeline.core import DownloadMethod, Pipeline\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/stanza/pipeline/core.py\", line 17, in <module>\n",
      "    from stanza.models.common.doc import Document\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/stanza/models/common/doc.py\", line 17, in <module>\n",
      "    from stanza.models.common.utils import misc_to_space_after, space_after_to_misc, misc_to_space_before, space_before_to_misc\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/stanza/models/common/utils.py\", line 19, in <module>\n",
      "    import torch\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/linndfors/study/diploma/new_venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import stanza\n",
    "import random\n",
    "import logging\n",
    "import pymorphy3\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "# import tqdm\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# nlp = spacy.load(\"uk_ner_web_trf_13class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "first_names_with_sex_df = pd.read_csv(\"/Users/linndfors/study/diploma/ner_for_fem/data/util/first_names_frequency_popular.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_prompt_with_names(female_names, male_names):\n",
    "    updated_prompt = f\"\"\"\n",
    "Ви - експерт з обробки природної мови. Ваше завдання - змінити задане речення зі зміною статі, використовуючи словник анотацій у форматі {{\"слово\": \"його сутність(label) з NER\"}}. Дотримуйтесь таких правил:\n",
    "    1. Якщо зустрічається слово чоловічого роду з класу \"JOB\", змініть його на жіночий аналог, і навпаки для жіночого роду. \n",
    "       **Виняток**: якщо ця сутність класу \"JOB\" належить до **спільного роду** (наприклад, \"голова\", \"суддя\"), такі слова, а також усі пов'язані з ними залежні слова (імена, прикметники, дієслова тощо), **залишаються без змін**.\n",
    "    2. Якщо \"JOB\" було змінене, то змінити потрібно і сутність \"PERS\".\n",
    "    3. Якщо слова не відносятся до сутностей в анотаціях, то їх змінювати непотрібно.\n",
    "    Знайди в сутності \"PERS\" імʼя і:\n",
    "    а) якщо імʼя належить до чоловічого роду то зміни на жіноче, обране лише з наступних запропонованих варіантів: {female_names}.\n",
    "    б) якщо імʼя належить до жіночого роду то зміни на чоловіче, обране лише з наступних запропонованих варіантів: {male_names}.\n",
    "    Не можна використосувати інші імена, окрім запропонованих.\n",
    "    4. Зберігайте відмінки слів: якщо слово було, наприклад, у родовому відмінку (\"режисера\"), то його аналог має теж бути в родовому відмінку (\"режисерки\").\n",
    "    5. Зберігайте форму слова за числом: множина залишається множиною (\"власники\" → \"власниці\"), однина - одниною.\n",
    "    6. Забезпечте граматичну коректність речення, узгоджуючи змінені слова з контекстом.\n",
    "    7. Залиши всі інші знаки, пунктуації, символи, включаючи символи \"<\" і \">\", незмінними.\n",
    "    8. Як результат виведи змінене речення без жодних додаткових пояснень.\n",
    "\n",
    "    Приклад:\n",
    "        Input: Дмитро Петренко став новим адміністратором за наказом заступниці директора Тетяни Сірої, яка належить до прихильників радикальних методів. {{\"Дмитро Петренко\": \"PERS\", \"Тетяни Сірої\": \"PERS\", \"адміністратором\": \"JOB\", \"заступниці\": \"JOB\", \"директора\": \"JOB\"}}\n",
    "        Output: Марина Петренко стала новою адміністраторкою за наказом заступника директорки Володимира Сірого, який належить до прихильників радикальних методів.\n",
    "\n",
    "        Input: Сестри художника Бориса Мартинюка були відомими співачками, тому у Бориса не було часу проводити час з подругами. {{\"художника\": \"JOB\", \"Бориса Мартинюка\": \"PERS\", \"співачками\": \"JOB\", \"Бориса\": \"PERS\"}}\n",
    "        Output: Брати художниці Олени Мартинюк були відомими співаками, тому у Олени не було часу проводити час з подругами.\n",
    "        \n",
    "        Input: Суддя Марина зʼявилась запізно <.{{\"Суддя\": \"JOB\", \"Марина\": \"PERS\"}}\n",
    "        Otput: Суддя Марина зʼявилась запізно <.\n",
    "\"\"\"\n",
    "    return updated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_name(df, n, sex=None):\n",
    "    if sex:\n",
    "        df = df[df['sex'] == sex]\n",
    "    \n",
    "    names = df['name']\n",
    "    frequencies = df['freq']\n",
    "    \n",
    "    return list(np.random.choice(names, size=n, p=frequencies/np.sum(frequencies)))\n",
    "\n",
    "\n",
    "def change_gender(sentence):\n",
    "    male_names = generate_random_name(first_names_with_sex_df, 3, 'M')\n",
    "    female_names = generate_random_name(first_names_with_sex_df, 3, 'F')\n",
    "    print(\"male names:\", male_names)\n",
    "    print(\"female names:\", female_names)\n",
    "\n",
    "    gender_swap_prompt = fill_prompt_with_names(female_names, male_names)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": gender_swap_prompt},\n",
    "        {\"role\": \"user\", \"content\": sentence},\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", messages=messages, temperature=0.8, max_tokens=250, top_p=1\n",
    "    )\n",
    "\n",
    "    response_content = response.choices[0].message.content\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ann_files(directory):\n",
    "    ann_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ann\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                ann_files.append(file_path)\n",
    "\n",
    "    return ann_files\n",
    "\n",
    "def read_ann_files(directory):\n",
    "    ann_files = find_ann_files(directory)\n",
    "    job_title_sentences = []\n",
    "\n",
    "    for ann_file in ann_files:\n",
    "        with open(ann_file, \"r\", encoding=\"utf-8\") as ann_f:\n",
    "            for ann_l in ann_f:\n",
    "                ann_row = ann_l.split(\"\\t\")\n",
    "\n",
    "                try:\n",
    "                    if ann_row[1] == \"JOB\":\n",
    "                        job_title_sentences.append(ann_row)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "\n",
    "    return job_title_sentences\n",
    "\n",
    "def find_txt_files(directory):\n",
    "    txt_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                txt_files.append(file_path)\n",
    "\n",
    "    return txt_files\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    txt_files = find_txt_files(directory)\n",
    "    text = []\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        with open(txt_file, \"r\", encoding=\"utf-8\") as txt_f:\n",
    "            text.append(txt_f.read())\n",
    "\n",
    "    return text\n",
    "\n",
    "text_ng = read_txt_files(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/ng\")\n",
    "text_bruk = read_txt_files(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/bruk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ann_file(ann_file):\n",
    "    entities = []\n",
    "\n",
    "    with open(ann_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            label = parts[1]\n",
    "            start = parts[2]\n",
    "            end = parts[3]\n",
    "            text = parts[4]\n",
    "\n",
    "            entities.append({\"text\": text, \"start\": start, \"end\": end, \"label\": label})\n",
    "\n",
    "    return entities\n",
    "\n",
    "\n",
    "def extract_entities(txt_file, ann_file):\n",
    "    labeled_sentences_list = []\n",
    "    sentences = []\n",
    "\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentence_lines = f.readlines()\n",
    "\n",
    "    entities = parse_ann_file(ann_file)\n",
    "\n",
    "    for sentence in sentence_lines:\n",
    "\n",
    "        labeled_dict = {}\n",
    "        job = False\n",
    "        sentence = sentence.strip()\n",
    "\n",
    "        for ent in entities:\n",
    "            if re.search(rf\"\\b{re.escape(ent['text'])}\\b\", sentence):\n",
    "                labeled_dict[ent[\"text\"]] = ent[\"label\"]\n",
    "                if ent[\"label\"] == \"JOB\":\n",
    "                    job = True\n",
    "\n",
    "        if job:\n",
    "            labeled_sentences_list.append(labeled_dict)\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    return labeled_sentences_list, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data_dict = {}\n",
    "    current_label = None\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line in [\"DEV\", \"TEST\"]:\n",
    "                current_label = line\n",
    "                data_dict[current_label] = []\n",
    "            elif current_label:\n",
    "                if line:\n",
    "                    data_dict[current_label].append(line)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "file_path = \"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/dev-test-split.txt\"\n",
    "data_dict = read_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory):\n",
    "    dev_list = []\n",
    "    test_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                if file.split(\".\")[0] in list(data_dict[\"DEV\"]):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    dev_list.append(file_path)\n",
    "                elif file.split(\".\")[0] in list(data_dict[\"TEST\"]):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    test_list.append(file_path)\n",
    "\n",
    "    return dev_list, test_list\n",
    "\n",
    "\n",
    "def read_files(txt_files):\n",
    "    text = \"\"\n",
    "    for txt_file in txt_files:\n",
    "        with open(txt_file, \"r\", encoding=\"utf-8\") as txt_f:\n",
    "            text += txt_f.read()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruk_dev, bruk_test = find_files(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/bruk\")\n",
    "ng_dev, ng_test = find_files(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/ng\")\n",
    "\n",
    "dev_files = bruk_dev + ng_dev\n",
    "test_files = bruk_test + ng_test\n",
    "\n",
    "ng_files = ng_dev + ng_test\n",
    "bruk_files = bruk_dev + bruk_test \n",
    "\n",
    "dev_files_text = read_files(dev_files)\n",
    "test_files_text = read_files(test_files)\n",
    "\n",
    "dev_ng_text = read_files(ng_dev)\n",
    "test_ng_text = read_files(ng_test)\n",
    "\n",
    "dev_bruk_text = read_files(bruk_dev)\n",
    "test_bruk_text = read_files(bruk_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_with_job_titles(txt_file_names):\n",
    "\n",
    "    sentence_with_jobs = {}\n",
    "\n",
    "    for txt_file in txt_file_names:\n",
    "        ann_file = txt_file.replace(\".txt\", \".ann\")\n",
    "        labeled_sentences_list, sentences = extract_entities(txt_file, ann_file)\n",
    "        for i in range(len(sentences)):\n",
    "            sentence_with_jobs[sentences[i]] = labeled_sentences_list[i]\n",
    "\n",
    "    return sentence_with_jobs\n",
    "\n",
    "test_sentences_with_jobs = get_sentences_with_job_titles(test_files)\n",
    "dev_sentences_with_jobs = get_sentences_with_job_titles(dev_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_jobs = get_sentences_with_job_titles(ng_files)\n",
    "bruk_jobs = get_sentences_with_job_titles(bruk_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ng_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bruk_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_jobs_ng = []\n",
    "\n",
    "for x, val in ng_jobs.items():\n",
    "    for ent, lab in val.items():\n",
    "        if lab == \"PERS\":\n",
    "            list_of_jobs_ng.append(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_jobs_bruk = []\n",
    "\n",
    "for x, val in bruk_jobs.items():\n",
    "    for ent, lab in val.items():\n",
    "        if lab == \"PERS\":\n",
    "            list_of_jobs_bruk.append(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ng_pers_orig_only_jobs_sents.txt', 'w', encoding='utf-8') as f:\n",
    "    for item in list_of_jobs_ng:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/Users/linndfors/study/diploma/ner_for_fem/JSON_files/test_sentences_with_jobs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(test_sentences_with_jobs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# with open(\"/Users/linndfors/study/diploma/ner_for_fem/JSON_files/dev_sentences_with_jobs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(dev_sentences_with_jobs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Gender-swapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_swaped_pairs_dev = {}\n",
    "\n",
    "for sentence, ann_dict in tqdm(\n",
    "    dev_sentences_with_jobs.items(), desc=\"Processing sentences\"\n",
    "):\n",
    "    try:\n",
    "        filtered_ann_dict = {key: value for key, value in ann_dict.items() if value in {'PERS', 'JOB'}}\n",
    "        dev_raw_and_annotated = sentence + \"\\n\" + str(filtered_ann_dict)\n",
    "        # print(test_raw_and_annotated)\n",
    "        output = change_gender(dev_raw_and_annotated)\n",
    "        print(dev_raw_and_annotated)\n",
    "        print(output)\n",
    "        print(\"-------------------------------------\")\n",
    "        gender_swaped_pairs_dev[sentence] = output\n",
    "    except Exception as e:\n",
    "        print(\"error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_swaped_df = pd.DataFrame(\n",
    "    gender_swaped_pairs_dev.items(), \n",
    "    columns=[\"original\", \"swapped\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>swapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Виставу за п'єсою російського класика Льва Тол...</td>\n",
       "      <td>Виставу за п'єсою російського класика Льва Тол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Віртуозні Лесь Задніпровський – князь Абрезков...</td>\n",
       "      <td>Віртуозні Ганна Задніпровська – княгиня Абрезк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Старша в Києві , одружена з військовим , чолов...</td>\n",
       "      <td>Старша в Києві , одружена з військовою , чолов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ні , не так - автор статті , позаштатний корес...</td>\n",
       "      <td>Ні , не так - авторка статті , позаштатна коре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>І лектори в сірих піджаках із червоними парткв...</td>\n",
       "      <td>І лектори в сірих піджаках із червоними парткв...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  Виставу за п'єсою російського класика Льва Тол...   \n",
       "1  Віртуозні Лесь Задніпровський – князь Абрезков...   \n",
       "2  Старша в Києві , одружена з військовим , чолов...   \n",
       "3  Ні , не так - автор статті , позаштатний корес...   \n",
       "4  І лектори в сірих піджаках із червоними парткв...   \n",
       "\n",
       "                                             swapped  \n",
       "0  Виставу за п'єсою російського класика Льва Тол...  \n",
       "1  Віртуозні Ганна Задніпровська – княгиня Абрезк...  \n",
       "2  Старша в Києві , одружена з військовою , чолов...  \n",
       "3  Ні , не так - авторка статті , позаштатна коре...  \n",
       "4  І лектори в сірих піджаках із червоними парткв...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_swaped_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset for annotation project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"/Users/linndfors/study/diploma/ner_for_fem/annotation_project/sentences_for_annotation/dev_swapped_sentences_with_names_frequencies.csv\"\n",
    "gender_swaped_df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add old annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read swapped sentences\n",
    "import csv\n",
    "\n",
    "orig_and_changed_dict = {}\n",
    "\n",
    "with open(\"/Users/linndfors/study/diploma/ner_for_fem/annotation_project/sentences_for_annotation/dev_swapped_sentences_with_names_frequencies.csv\", mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    \n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        key = row[1]\n",
    "        value = row[2]\n",
    "        orig_and_changed_dict[key] = value\n",
    "\n",
    "with open(\"/Users/linndfors/study/diploma/ner_for_fem/JSON_files/test_sentences_with_jobs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_sentences_with_jobs = json.load(f)\n",
    "\n",
    "with open(\"/Users/linndfors/study/diploma/ner_for_fem/JSON_files/dev_sentences_with_jobs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dev_sentences_with_jobs = json.load(f)\n",
    "\n",
    "def set_annotattions(original_sent):\n",
    "    if original_sent in dev_sentences_with_jobs.keys():\n",
    "        annotations = dev_sentences_with_jobs[original_sent] \n",
    "        filtered_annotations = {key: value for key, value in annotations.items() if value in {'PERS', 'JOB'}}\n",
    "        return filtered_annotations\n",
    "    return None\n",
    "\n",
    "gender_swaped_df['old_Annotations'] = gender_swaped_df.apply(lambda x: set_annotattions(x['original']), axis=1)\n",
    "gender_swaped_df.to_csv(\"/Users/linndfors/study/diploma/ner_for_fem/annotation_project/sentences_for_annotation/dev_swapped_with_ann_with_names_changed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation for .ann files reseting (for the Gender-balanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_swapped_df = pd.read_csv(\"/Users/linndfors/study/diploma/ner_for_fem/annotation_project/sentences_after_annotation/dev_swapped.csv\")\n",
    "test_swapped_df = pd.read_csv(\"/Users/linndfors/study/diploma/ner_for_fem/annotation_project/sentences_after_annotation/test_swapped.csv\")\n",
    "\n",
    "swapped_df = pd.concat([dev_swapped_df, test_swapped_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Оригінальне речення</th>\n",
       "      <th>Змінене речення</th>\n",
       "      <th>Анотації</th>\n",
       "      <th>Коректність речення</th>\n",
       "      <th>Виправлене речення</th>\n",
       "      <th>Помічник/ця</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Виставу за п'єсою російського класика Льва Тол...</td>\n",
       "      <td>Виставу за п'єсою російського класика Льва Тол...</td>\n",
       "      <td>{'Льва Толстого': 'PERS', 'режисера': 'JOB', '...</td>\n",
       "      <td>Містить помилки</td>\n",
       "      <td>Виставу за п'єсою російської класикині Марії Т...</td>\n",
       "      <td>Оля Н</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Віртуозні Лесь Задніпровський – князь Абрезков...</td>\n",
       "      <td>Віртуозні Ганна Задніпровська – княгиня Абрезк...</td>\n",
       "      <td>{'Лесь Задніпровський': 'PERS', 'князь': 'JOB'...</td>\n",
       "      <td>Містить помилки</td>\n",
       "      <td>Віртуозні Ганна Задніпровська – княгиня Абрезк...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Старша в Києві , одружена з військовим , чолов...</td>\n",
       "      <td>Старша в Києві , одружена з військовою , чолов...</td>\n",
       "      <td>{'військовим': 'JOB'}</td>\n",
       "      <td>Містить помилки</td>\n",
       "      <td>Старша в Києві , одружена з військовою , жінка...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ні , не так - автор статті , позаштатний корес...</td>\n",
       "      <td>Ні , не так - авторка статті , позаштатна коре...</td>\n",
       "      <td>{'позаштатний кореспондент': 'JOB'}</td>\n",
       "      <td>Правильне</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>І лектори в сірих піджаках із червоними парткв...</td>\n",
       "      <td>І лектори в сірих піджаках із червоними парткв...</td>\n",
       "      <td>{'священиків': 'JOB'}</td>\n",
       "      <td>Правильне</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Оригінальне речення  \\\n",
       "0  Виставу за п'єсою російського класика Льва Тол...   \n",
       "1  Віртуозні Лесь Задніпровський – князь Абрезков...   \n",
       "2  Старша в Києві , одружена з військовим , чолов...   \n",
       "3  Ні , не так - автор статті , позаштатний корес...   \n",
       "4  І лектори в сірих піджаках із червоними парткв...   \n",
       "\n",
       "                                     Змінене речення  \\\n",
       "0  Виставу за п'єсою російського класика Льва Тол...   \n",
       "1  Віртуозні Ганна Задніпровська – княгиня Абрезк...   \n",
       "2  Старша в Києві , одружена з військовою , чолов...   \n",
       "3  Ні , не так - авторка статті , позаштатна коре...   \n",
       "4  І лектори в сірих піджаках із червоними парткв...   \n",
       "\n",
       "                                            Анотації Коректність речення  \\\n",
       "0  {'Льва Толстого': 'PERS', 'режисера': 'JOB', '...     Містить помилки   \n",
       "1  {'Лесь Задніпровський': 'PERS', 'князь': 'JOB'...     Містить помилки   \n",
       "2                              {'військовим': 'JOB'}     Містить помилки   \n",
       "3                {'позаштатний кореспондент': 'JOB'}           Правильне   \n",
       "4                              {'священиків': 'JOB'}           Правильне   \n",
       "\n",
       "                                  Виправлене речення Помічник/ця  \n",
       "0  Виставу за п'єсою російської класикині Марії Т...       Оля Н  \n",
       "1  Віртуозні Ганна Задніпровська – княгиня Абрезк...         NaN  \n",
       "2  Старша в Києві , одружена з військовою , жінка...         NaN  \n",
       "3                                                NaN         NaN  \n",
       "4                                                NaN         NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swapped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "swapped_df['gender-swapped'] = swapped_df.apply(lambda x: x['Виправлене речення'] if x['Виправлене речення'] and x['Коректність речення']=='Містить помилки' else x['Змінене речення'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Оригінальне речення</th>\n",
       "      <th>Змінене речення</th>\n",
       "      <th>Анотації</th>\n",
       "      <th>Коректність речення</th>\n",
       "      <th>Виправлене речення</th>\n",
       "      <th>Помічник/ця</th>\n",
       "      <th>gender-swapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Оригінальне речення, Змінене речення, Анотації, Коректність речення, Виправлене речення, Помічник/ця, gender-swapped]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swapped_df[(swapped_df['Коректність речення']=='Містить помилки') & (swapped_df['Виправлене речення'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Оригінальне речення</th>\n",
       "      <th>Змінене речення</th>\n",
       "      <th>Анотації</th>\n",
       "      <th>Коректність речення</th>\n",
       "      <th>Виправлене речення</th>\n",
       "      <th>Помічник/ця</th>\n",
       "      <th>gender-swapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Виставу за п'єсою російського класика Льва Тол...</td>\n",
       "      <td>Виставу за п'єсою російського класика Льва Тол...</td>\n",
       "      <td>{'Льва Толстого': 'PERS', 'режисера': 'JOB', '...</td>\n",
       "      <td>Містить помилки</td>\n",
       "      <td>Виставу за п'єсою російської класикині Марії Т...</td>\n",
       "      <td>Оля Н</td>\n",
       "      <td>Виставу за п'єсою російської класикині Марії Т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Віртуозні Лесь Задніпровський – князь Абрезков...</td>\n",
       "      <td>Віртуозні Ганна Задніпровська – княгиня Абрезк...</td>\n",
       "      <td>{'Лесь Задніпровський': 'PERS', 'князь': 'JOB'...</td>\n",
       "      <td>Містить помилки</td>\n",
       "      <td>Віртуозні Ганна Задніпровська – княгиня Абрезк...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Віртуозні Ганна Задніпровська – княгиня Абрезк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Старша в Києві , одружена з військовим , чолов...</td>\n",
       "      <td>Старша в Києві , одружена з військовою , чолов...</td>\n",
       "      <td>{'військовим': 'JOB'}</td>\n",
       "      <td>Містить помилки</td>\n",
       "      <td>Старша в Києві , одружена з військовою , жінка...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Старша в Києві , одружена з військовою , жінка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ні , не так - автор статті , позаштатний корес...</td>\n",
       "      <td>Ні , не так - авторка статті , позаштатна коре...</td>\n",
       "      <td>{'позаштатний кореспондент': 'JOB'}</td>\n",
       "      <td>Правильне</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ні , не так - авторка статті , позаштатна коре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>І лектори в сірих піджаках із червоними парткв...</td>\n",
       "      <td>І лектори в сірих піджаках із червоними парткв...</td>\n",
       "      <td>{'священиків': 'JOB'}</td>\n",
       "      <td>Правильне</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>І лектори в сірих піджаках із червоними парткв...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Оригінальне речення  \\\n",
       "0  Виставу за п'єсою російського класика Льва Тол...   \n",
       "1  Віртуозні Лесь Задніпровський – князь Абрезков...   \n",
       "2  Старша в Києві , одружена з військовим , чолов...   \n",
       "3  Ні , не так - автор статті , позаштатний корес...   \n",
       "4  І лектори в сірих піджаках із червоними парткв...   \n",
       "\n",
       "                                     Змінене речення  \\\n",
       "0  Виставу за п'єсою російського класика Льва Тол...   \n",
       "1  Віртуозні Ганна Задніпровська – княгиня Абрезк...   \n",
       "2  Старша в Києві , одружена з військовою , чолов...   \n",
       "3  Ні , не так - авторка статті , позаштатна коре...   \n",
       "4  І лектори в сірих піджаках із червоними парткв...   \n",
       "\n",
       "                                            Анотації Коректність речення  \\\n",
       "0  {'Льва Толстого': 'PERS', 'режисера': 'JOB', '...     Містить помилки   \n",
       "1  {'Лесь Задніпровський': 'PERS', 'князь': 'JOB'...     Містить помилки   \n",
       "2                              {'військовим': 'JOB'}     Містить помилки   \n",
       "3                {'позаштатний кореспондент': 'JOB'}           Правильне   \n",
       "4                              {'священиків': 'JOB'}           Правильне   \n",
       "\n",
       "                                  Виправлене речення Помічник/ця  \\\n",
       "0  Виставу за п'єсою російської класикині Марії Т...       Оля Н   \n",
       "1  Віртуозні Ганна Задніпровська – княгиня Абрезк...         NaN   \n",
       "2  Старша в Києві , одружена з військовою , жінка...         NaN   \n",
       "3                                                NaN         NaN   \n",
       "4                                                NaN         NaN   \n",
       "\n",
       "                                      gender-swapped  \n",
       "0  Виставу за п'єсою російської класикині Марії Т...  \n",
       "1  Віртуозні Ганна Задніпровська – княгиня Абрезк...  \n",
       "2  Старша в Києві , одружена з військовою , жінка...  \n",
       "3  Ні , не так - авторка статті , позаштатна коре...  \n",
       "4  І лектори в сірих піджаках із червоними парткв...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swapped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_and_changed_dict = dict(zip(swapped_df['Оригінальне речення'], swapped_df['gender-swapped']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence to change: 24047\n"
     ]
    }
   ],
   "source": [
    "# change original text with the sentences we gender-swapped (sentences with JOB TITLEs)\n",
    "all_files_text = dev_files_text + test_files_text\n",
    "all_sent = all_files_text.split(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Sentence to change:\", len(all_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_punctuation(text):\n",
    "    text = re.sub(r'\\s+([,()?!:])', r'\\1', text)\n",
    "    text = re.sub(r'\\s+(\\.)', r'\\1', text)\n",
    "    \n",
    "    text = re.sub(r'(?<!\\s)([,.()?!:])', r' \\1', text)\n",
    "    \n",
    "    text = re.sub(r'([,()?!:])(?!\\s)', r'\\1 ', text)\n",
    "    \n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_orig_text_to_gend_swapped(txt_file, list_of_manually_changed_files):\n",
    "    # create a new files with the old name but new text with swapped sentences. also add old ann file\n",
    "    file_and_text_dict = {}\n",
    "    file_need_to_be_changed = None\n",
    "\n",
    "    ann_file = txt_file.replace(\".txt\", \".ann\")\n",
    "    changed_ann_file = ann_file.replace('ng', \"ng_changed\")\n",
    "    changed_ann_file= changed_ann_file.replace('bruk', \"bruk_changed\")\n",
    "    shutil.copyfile(ann_file, changed_ann_file)\n",
    "\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as txt_f:\n",
    "        text = txt_f.read()\n",
    "\n",
    "        new_text = []\n",
    "\n",
    "        for x in text.split(\"\\n\"):\n",
    "            if x:\n",
    "                if x in orig_and_changed_dict.keys():\n",
    "                    new_text.append(orig_and_changed_dict[x])\n",
    "                    file_need_to_be_changed = txt_file\n",
    "                else:\n",
    "                    new_text.append(x)\n",
    "            else:\n",
    "                new_text.append(\"\")\n",
    "\n",
    "    \n",
    "    changed_txt_file = txt_file.replace('ng', \"ng_changed\")\n",
    "    changed_txt_file = changed_txt_file.replace('bruk', \"bruk_changed\")\n",
    "    if new_text:\n",
    "        if txt_file not in list_of_manually_changed_files:\n",
    "            joined_text = \"\\n\".join(new_text)\n",
    "            file_and_text_dict[changed_txt_file] = joined_text\n",
    "        else:\n",
    "            with open(changed_txt_file, 'r') as file:\n",
    "                changed_text = file.read()\n",
    "            file_and_text_dict[changed_txt_file] = changed_text    \n",
    "            print(\"add:\", changed_txt_file)    \n",
    "\n",
    "    return file_and_text_dict, file_need_to_be_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_from_ann_files(directory):\n",
    "    ann_files = find_ann_files(directory)\n",
    "    ann_files_content = {}\n",
    "\n",
    "    for ann_file in ann_files:\n",
    "        with open(ann_file, \"r\", encoding=\"utf-8\") as ann_f:\n",
    "            rows = []\n",
    "            buffer = []\n",
    "            for line in ann_f:\n",
    "                line = line.strip()\n",
    "                if \"\\t\" in line:\n",
    "                    if buffer:\n",
    "                        rows.append(parse_annotation_line(\"\\n\".join(buffer)))\n",
    "                        buffer = []\n",
    "                    buffer.append(line)\n",
    "                else:\n",
    "                    buffer.append(line)\n",
    "            \n",
    "            if buffer:\n",
    "                rows.append(parse_annotation_line(\"\\n\".join(buffer)))\n",
    "\n",
    "        ann_files_content[ann_file] = rows\n",
    "\n",
    "    return ann_files_content\n",
    "\n",
    "def parse_annotation_line(line):\n",
    "    \"\"\"\n",
    "    Parses a single annotation line, including multi-line entities.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = line.split(\"\\t\", maxsplit=4)\n",
    "        ind, label, start, end = parts[:4]\n",
    "        ent = parts[4] if len(parts) > 4 else \"\"\n",
    "        return {\"ind\": ind, \"label\": label, \"start\": int(start), \"end\": int(end), \"ent\": ent.replace(\"\\n\", \" \")}\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing annotation line: {line}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def tokenize_with_indices(text):\n",
    "    \"\"\"Tokenizes text and returns a list of (token, start, end).\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [(token.text, token.idx, token.idx + len(token)) for token in doc]\n",
    "\n",
    "def create_new_ann_file(orig_file_name, changed_file_name, changed_text, ann_files):\n",
    "    with open(orig_file_name, 'r') as file:\n",
    "        original_text = file.read()\n",
    "\n",
    "    old_ann_file = orig_file_name.replace(\".txt\", \".ann\")\n",
    "    original_annotations = ann_files[old_ann_file]\n",
    "\n",
    "    original_tokens = tokenize_with_indices(original_text)\n",
    "    changed_tokens = tokenize_with_indices(changed_text)\n",
    "\n",
    "    dict_for_changed_ann = {}\n",
    "    index_offset_map = {}\n",
    "    current_offset = 0\n",
    "    orig_char_index = 0\n",
    "    changed_char_index = 0\n",
    "\n",
    "    orig_token_index = 0\n",
    "    changed_token_index = 0\n",
    "\n",
    "    while orig_char_index < len(original_text) and changed_char_index < len(changed_text):\n",
    "        index_offset_map[orig_char_index] = current_offset\n",
    "\n",
    "        if orig_token_index < len(original_tokens) and changed_token_index < len(changed_tokens):\n",
    "            orig_token = original_tokens[orig_token_index]\n",
    "            changed_token = changed_tokens[changed_token_index]\n",
    "\n",
    "            if orig_char_index == orig_token[1] and changed_char_index == changed_token[1]:\n",
    "                if orig_token[0] != changed_token[0]:\n",
    "                    print(\"offest changed for: \", changed_token[0], orig_token[0])\n",
    "                    current_offset += len(changed_token[0]) - len(orig_token[0])\n",
    "\n",
    "                orig_char_index += len(orig_token[0])\n",
    "                changed_char_index += len(changed_token[0])\n",
    "\n",
    "                if orig_char_index == orig_token[2]:\n",
    "                    orig_token_index += 1\n",
    "                if changed_char_index == changed_token[2]:\n",
    "                    changed_token_index += 1\n",
    "            else:\n",
    "                orig_char_index += 1\n",
    "                changed_char_index += 1\n",
    "        else:\n",
    "            index_offset_map[orig_char_index] = current_offset\n",
    "            orig_char_index += 1\n",
    "\n",
    "    while orig_char_index < len(original_text):\n",
    "        index_offset_map[orig_char_index] = current_offset\n",
    "        orig_char_index += 1\n",
    "\n",
    "    for annotation in original_annotations:\n",
    "        orig_start = annotation['start']\n",
    "        orig_end = annotation['end']\n",
    "        new_start = orig_start + index_offset_map.get(orig_start, 0)\n",
    "        new_end = orig_end + index_offset_map.get(orig_end, 0)\n",
    "\n",
    "        new_ent = changed_text[new_start:new_end]\n",
    "        dict_for_changed_ann[annotation['ind']] = (new_ent, (new_start, new_end))\n",
    "\n",
    "    return dict_for_changed_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_files = dict_from_ann_files(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/ng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ann_dict = {}\n",
    "\n",
    "files_need_to_be_changed = set()\n",
    "\n",
    "for old_file in tqdm(ng_files): # bruk_files\n",
    "    ann_file = old_file.replace(\".txt\", \".ann\")\n",
    "    # ann_file = ann_file.replace(\"ng\", \"ng_changed\")\n",
    "    new_file_new_dev_dict,          file_need_to_be_changed = change_orig_text_to_gend_swapped(old_file)\n",
    "\n",
    "    if file_need_to_be_changed:\n",
    "        files_need_to_be_changed.add(file_need_to_be_changed)\n",
    "\n",
    "    for file_path, content in new_file_new_dev_dict.items():\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(content)\n",
    "\n",
    "        dict_for_changed_ann = {}\n",
    "        if old_file in files_need_to_be_changed:\n",
    "            dict_for_changed_ann = create_new_ann_file(old_file, file_path, content, ann_files_1)\n",
    "\n",
    "        for x in ann_files_1[ann_file]:\n",
    "            if x['ind'] in dict_for_changed_ann.keys():\n",
    "                x['end'] = dict_for_changed_ann[x['ind']][1][1]\n",
    "                x['start'] = dict_for_changed_ann[x['ind']][1][0]\n",
    "                new_ent = dict_for_changed_ann[x['ind']][0]\n",
    "                x['ent'] = new_ent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:00<00:00, 1221.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def write_ann_files_from_dict(ann_files_content):\n",
    "    for ann_file, annotations in tqdm(ann_files_content.items()):\n",
    "        relevant_txt_file = ann_file.replace(\".ann\", \".txt\")\n",
    "        if relevant_txt_file in files_need_to_be_changed:\n",
    "            # ann_file = ann_file.replace(\"bruk/\", \"bruk_changed/\")\n",
    "            ann_file = ann_file.replace(\"ng/\", \"ng_changed/\")\n",
    "            with open(ann_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                for annotation in annotations:\n",
    "                    line = f\"{annotation['ind']}\\t{annotation['label']}\\t{annotation['start']}\\t{annotation['end']}\\t{annotation['ent']}\\n\"\n",
    "                    f.write(line)\n",
    "\n",
    "write_ann_files_from_dict(ann_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
