{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is created for splitting JOB and PERS entities by Gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 14:18:51 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d153823c104e3eae0e4f9798912367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 14:18:51 INFO: Downloaded file to /Users/linndfors/stanza_resources/resources.json\n",
      "2025-04-24 14:18:52 INFO: Loading these models for language: uk (Ukrainian):\n",
      "===========================\n",
      "| Processor | Package     |\n",
      "---------------------------\n",
      "| tokenize  | iu          |\n",
      "| mwt       | iu          |\n",
      "| pos       | iu_charlm   |\n",
      "| lemma     | iu_nocharlm |\n",
      "| depparse  | iu_charlm   |\n",
      "===========================\n",
      "\n",
      "2025-04-24 14:18:52 INFO: Using device: cpu\n",
      "2025-04-24 14:18:52 INFO: Loading: tokenize\n",
      "2025-04-24 14:18:54 INFO: Loading: mwt\n",
      "2025-04-24 14:18:54 INFO: Loading: pos\n",
      "2025-04-24 14:19:00 INFO: Loading: lemma\n",
      "2025-04-24 14:19:01 INFO: Loading: depparse\n",
      "2025-04-24 14:19:01 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import pymorphy3\n",
    "import pymorphy2\n",
    "\n",
    "nlp = stanza.Pipeline('uk', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "\n",
    "# # stanza.download('uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel_dataset_ng_dataset = pd.read_csv(\"/Users/linndfors/study/diploma/ner_for_fem/data/csv_files_with_par_sentences/ng_parallel.csv\")\n",
    "# parallel_dataset_bruk_dataset = pd.read_csv(\"/Users/linndfors/study/diploma/ner_for_fem/data/csv_files_with_par_sentences/bruk_parallel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>orig_sent_id</th>\n",
       "      <th>changed_sentence</th>\n",
       "      <th>changed_sent_id</th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>orig_ann</th>\n",
       "      <th>changed_ann</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Його редактором був поет-символіст Яків Савчен...</td>\n",
       "      <td>46</td>\n",
       "      <td>Його редакторкою була поетеса-символістка Анже...</td>\n",
       "      <td>46</td>\n",
       "      <td>e5e76a8efa0f.txt</td>\n",
       "      <td>{'T30': ('поет-символіст', 'JOB')}</td>\n",
       "      <td>{'T30': ('поетеса-символістка', 'JOB')}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Міжпредметні паралелі . Маніфест футуристів ск...</td>\n",
       "      <td>62</td>\n",
       "      <td>Міжпредметні паралелі . Маніфест футуристок ск...</td>\n",
       "      <td>62</td>\n",
       "      <td>e5e76a8efa0f.txt</td>\n",
       "      <td>{'T49': ('поет', 'JOB')}</td>\n",
       "      <td>{'T49': ('поетеса', 'JOB')}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Помітною була організація « Гарт » ( 1923 — 19...</td>\n",
       "      <td>96</td>\n",
       "      <td>Помітною була організація « Гарт » ( 1923 — 19...</td>\n",
       "      <td>96</td>\n",
       "      <td>e5e76a8efa0f.txt</td>\n",
       "      <td>{'T104': ('поет', 'JOB')}</td>\n",
       "      <td>{'T104': ('поетка', 'JOB')}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Її очолив байкар і прозаїк Сергій Пилипенко .</td>\n",
       "      <td>127</td>\n",
       "      <td>Її очолила байкарка і прозаїкиня Марія Пилипен...</td>\n",
       "      <td>127</td>\n",
       "      <td>e5e76a8efa0f.txt</td>\n",
       "      <td>{'T143': ('байкар', 'JOB'), 'T144': ('прозаїк'...</td>\n",
       "      <td>{'T143': ('байкарка', 'JOB'), 'T144': ('прозаї...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>У Галицько-Волинському літописі згадується спі...</td>\n",
       "      <td>171</td>\n",
       "      <td>У Галицько-Волинському літописі згадується спі...</td>\n",
       "      <td>171</td>\n",
       "      <td>e5e76a8efa0f.txt</td>\n",
       "      <td>{'T218': ('співець', 'JOB')}</td>\n",
       "      <td>{'T218': ('співчиня', 'JOB')}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_sentence  orig_sent_id  \\\n",
       "0  Його редактором був поет-символіст Яків Савчен...            46   \n",
       "1  Міжпредметні паралелі . Маніфест футуристів ск...            62   \n",
       "2  Помітною була організація « Гарт » ( 1923 — 19...            96   \n",
       "3      Її очолив байкар і прозаїк Сергій Пилипенко .           127   \n",
       "4  У Галицько-Волинському літописі згадується спі...           171   \n",
       "\n",
       "                                    changed_sentence  changed_sent_id  \\\n",
       "0  Його редакторкою була поетеса-символістка Анже...               46   \n",
       "1  Міжпредметні паралелі . Маніфест футуристок ск...               62   \n",
       "2  Помітною була організація « Гарт » ( 1923 — 19...               96   \n",
       "3  Її очолила байкарка і прозаїкиня Марія Пилипен...              127   \n",
       "4  У Галицько-Волинському літописі згадується спі...              171   \n",
       "\n",
       "  original_file_name                                           orig_ann  \\\n",
       "0   e5e76a8efa0f.txt                 {'T30': ('поет-символіст', 'JOB')}   \n",
       "1   e5e76a8efa0f.txt                           {'T49': ('поет', 'JOB')}   \n",
       "2   e5e76a8efa0f.txt                          {'T104': ('поет', 'JOB')}   \n",
       "3   e5e76a8efa0f.txt  {'T143': ('байкар', 'JOB'), 'T144': ('прозаїк'...   \n",
       "4   e5e76a8efa0f.txt                       {'T218': ('співець', 'JOB')}   \n",
       "\n",
       "                                         changed_ann  \n",
       "0            {'T30': ('поетеса-символістка', 'JOB')}  \n",
       "1                        {'T49': ('поетеса', 'JOB')}  \n",
       "2                        {'T104': ('поетка', 'JOB')}  \n",
       "3  {'T143': ('байкарка', 'JOB'), 'T144': ('прозаї...  \n",
       "4                      {'T218': ('співчиня', 'JOB')}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parallel_dataset_bruk_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split: Female, Male, Common genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/linndfors/study/diploma/other github repo/uk-gender-word-mapper/common_gender_words_list.txt') as file:\n",
    "    common_gender_words_list = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "with open('/Users/linndfors/study/diploma/other github repo/uk-gender-word-mapper/male_words_list.txt') as file:\n",
    "    male_list = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "with open('/Users/linndfors/study/diploma/other github repo/uk-gender-word-mapper/female_words_list.txt') as file:\n",
    "    female_list = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "gender_dict_df = pd.read_csv(\"/Users/linndfors/study/diploma/other github repo/uk-gender-word-mapper/gender_pairs_dictionary.csv\")\n",
    "\n",
    "gender_dict = {'male': [], 'female': []}\n",
    "\n",
    "for _, row in gender_dict_df.iterrows():\n",
    "    gender_dict['male'].append(row['male'])\n",
    "    female_values = [f.strip() for f in row['female'].split(',')]\n",
    "    gender_dict['female'].extend(female_values)\n",
    "\n",
    "gender_dict['female'] = list(set(gender_dict['female']))\n",
    "\n",
    "# exception that is not in the dict but obviously related to on of the gender\n",
    "# exceptions_common = [\"судді\",  \"глава\", \"голова\", \"керівництво\", \"в. о.\", \"головою\"]\n",
    "# exceptions_male = ['ієромонах', 'прокурор', 'віце-премʼєр', 'премʼєр', 'начальник', 'міністр', 'директор', 'підрядник', 'генпідрядник', 'керівник', 'головнокомандувач']\n",
    "# exceptions_female = ['премʼєрка', 'докторка', 'докторантка', 'директорка', 'міністерка', 'керівниця', 'начальниця', 'начальницю', 'генпідрядниця', 'прокурорка', 'ректорка']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for edgecases, when I cannot extract lemma\n",
    "\n",
    "def parse_output(ent):\n",
    "    noun_dict = {\n",
    "        \"хліборобок\": \"хліборобка\",\n",
    "    \"службовиці\": \"службовиця\",\n",
    "    \"аграрія\": \"аграрій\",\n",
    "    \"математикині\": \"математикиня\",\n",
    "    \"урядовиці\": \"урядовиця\",\n",
    "    \"філософині\": \"філософиня\",\n",
    "    \"педагогині\": \"педагогиня\",\n",
    "    \"мера\": \"мер\"\n",
    "    }\n",
    "    if ent in noun_dict.keys():\n",
    "        return noun_dict[ent]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_word(text):\n",
    "    if \"-\" in text:\n",
    "        parts = text.split(\"-\")\n",
    "        main_word = parts[-1]\n",
    "        doc = nlp(main_word)\n",
    "        for sentence in doc.sentences:\n",
    "            for word in sentence.words:\n",
    "                return word.lemma\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            if word.head == 0:\n",
    "                main_word = word\n",
    "                if main_word.text in {\"рок\", \"анти\", \"псевдо\", \"віце\", \"топ\"}:\n",
    "                    continue\n",
    "                return main_word.lemma\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            return word.lemma\n",
    "        \n",
    "def extract_job_gender(entity):\n",
    "    entity = entity.lower()\n",
    "    job = nlp(entity)\n",
    "    join_sign = \" \" if \" \" in entity else (\"\" if \"-\" in entity else \"\")\n",
    "    job_ent_list = [word.lemma for sent in job.sentences for word in sent.words]\n",
    "    job_lemma = join_sign.join(job_ent_list)\n",
    "\n",
    "    if len(job_ent_list) > 1:\n",
    "        job_lemma = extract_main_word(job_lemma)\n",
    "\n",
    "    words = entity.split()\n",
    "    lemmatized_words = []\n",
    "    for word in words:\n",
    "        parsed_word = morph.parse(word)[0]\n",
    "        if 'plur' in parsed_word.tag:\n",
    "            singular_form = parsed_word.inflect({'sing'}).word if parsed_word.inflect({'sing'}) else parsed_word.normal_form\n",
    "            lemmatized_words.append(singular_form)\n",
    "        else:\n",
    "            lemmatized_words.append(parsed_word.normal_form)\n",
    "            \n",
    "    job_lemma_pymorphy = join_sign.join(lemmatized_words)\n",
    "\n",
    "    if len(job_ent_list) > 1:\n",
    "        job_lemma_pymorphy = extract_main_word(job_lemma_pymorphy)\n",
    "\n",
    "    ent_forms = [entity, job_lemma, job_lemma_pymorphy]\n",
    "\n",
    "    custom_dict_ent_value = parse_output(entity)\n",
    "    if custom_dict_ent_value:\n",
    "        ent_forms.append(custom_dict_ent_value)\n",
    "\n",
    "    for word in words:\n",
    "        for common_word in exceptions_common:\n",
    "            if common_word == word or common_word == parse_output(word):\n",
    "                return \"common\", job_lemma\n",
    "            \n",
    "        for female_word in exceptions_female:\n",
    "            if female_word == word or female_word == parse_output(word):\n",
    "                return \"female\", job_lemma\n",
    "            \n",
    "        for male_word in exceptions_male:\n",
    "            if male_word == word or male_word == parse_output(word):\n",
    "                return \"male\", job_lemma\n",
    "        \n",
    "    for x in ent_forms:\n",
    "        if (x in gender_dict['female']) or (x in female_list) or (\"знавиця\" in x):\n",
    "            return \"female\", job_lemma\n",
    "        elif (x in gender_dict['male']) or (x in male_list) or (\"знавець\" in x) or (x==\"мера\"):\n",
    "            return \"male\", job_lemma\n",
    "        elif x in common_gender_words_list:\n",
    "            return \"common\", job_lemma\n",
    "        \n",
    "    # print(\"unkown for:\", entity, \" - \", job_lemma, \" - \", job_lemma_pymorphy)\n",
    "    return \"unknown_gender\", job_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def return_gendered_dict(parallel_dataset, annotation_col_name, swapped=0):\n",
    "    file_gender_dict = {\"male\": {}, \"female\": {}, \"common\": {}, \"unknown_gender\": {}}\n",
    "\n",
    "    total_job_counter = 0\n",
    "    job_list = []\n",
    "\n",
    "    for x, row in tqdm.tqdm(parallel_dataset.iterrows()):\n",
    "        filename = row['original_file_name']\n",
    "        if swapped:\n",
    "            filename = filename.replace(\".txt\", \"_1.txt\")\n",
    "        orig_annotation = row[annotation_col_name]\n",
    "\n",
    "        ann_str = orig_annotation.replace(\"'\", '\"')\n",
    "        ann_str = ann_str.replace(\"–\", '-')\n",
    "        json_ann = ast.literal_eval(ann_str)\n",
    "        \n",
    "        try:\n",
    "            for ent, feat in json_ann.items():\n",
    "                if feat[1] == 'JOB':\n",
    "                    total_job_counter += 1\n",
    "                    job_list.append(feat[0])\n",
    "                    gender_value, lemma_word = extract_job_gender(feat[0])\n",
    "                    \n",
    "                    if filename not in file_gender_dict[gender_value]:\n",
    "                        file_gender_dict[gender_value][filename] = [(ent, lemma_word)]\n",
    "                    else:\n",
    "                        file_gender_dict[gender_value][filename].append((ent, lemma_word))\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Issue with row: {row} - Error: {e}\")\n",
    "    return file_gender_dict, total_job_counter, job_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def return_gender_stat(total_job_counter, file_gender_dict):\n",
    "    print(\"total size:\", total_job_counter)\n",
    "\n",
    "    for gender_class, val in file_gender_dict.items():\n",
    "        print(\"================\")\n",
    "        \n",
    "        print(\"gender:\", gender_class)\n",
    "\n",
    "        gender_entities = []\n",
    "\n",
    "        print(\"number of files for the gender:\", len(file_gender_dict[gender_class]))\n",
    "        number_of_ents = 0\n",
    "        for files, ents in file_gender_dict[gender_class].items():\n",
    "            number_of_ents += len(ents)\n",
    "            gender_entities += [pair[1] for pair in ents]\n",
    "            \n",
    "        print(\"number of entities for the gender:\", number_of_ents)\n",
    "        print(\"percentage:\", number_of_ents/total_job_counter)\n",
    "\n",
    "        counter = Counter(gender_entities)\n",
    "\n",
    "        print(\"The most popular entity:\", counter.most_common(1)[0][0])\n",
    "\n",
    "        print(\"================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_files(file_gender_dict, source_dir):\n",
    "    female_files = []\n",
    "    male_files = []\n",
    "    common_files = []\n",
    "\n",
    "    for filename, gen_stat in file_gender_dict.items():\n",
    "        if len(list(gen_stat.keys())) == 1:\n",
    "            full_path = os.path.join(source_dir, filename)\n",
    "            gen = list(gen_stat.keys())[0]\n",
    "            # print(\"gen stat:\", gen_stat)\n",
    "            # print(\"gen:\", gen)\n",
    "            if gen == \"male\":\n",
    "                male_files.append(full_path)\n",
    "                # print(f\"add to {gen}\")\n",
    "            elif gen == \"female\":\n",
    "                female_files.append(full_path)\n",
    "                # print(f\"add to {gen}\")\n",
    "            elif gen == \"common\":\n",
    "                common_files.append(full_path)\n",
    "                # print(f\"add to {gen}\")\n",
    "\n",
    "    return female_files, male_files, common_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_gender_file_stat(file_gender_dict):\n",
    "    file_gen_stat_dict = {}\n",
    "\n",
    "    for gen, file_stat in file_gender_dict.items():\n",
    "        for filename, ents in file_stat.items():\n",
    "            if filename not in file_gen_stat_dict:\n",
    "                file_gen_stat_dict[filename] = {}\n",
    "            file_gen_stat_dict[filename][gen] = len(ents)\n",
    "    return file_gen_stat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify gender for entities from NER evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_entities(file_path):\n",
    "    \"\"\"\n",
    "    Reads a text file where each non‐empty line is an entity,\n",
    "    and returns a list of those entities (stripped of whitespace).\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list_balanced = read_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/results_of_evaluation/NER_JOB_class_results/balanced_fn.txt\")\n",
    "tp_list_balanced = read_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/results_of_evaluation/NER_JOB_class_results/balanced_tp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_tp, male_tp, common_tp, unknown_tp = [], [], [], []\n",
    "\n",
    "for ent in tqdm.tqdm(tp_list_balanced):\n",
    "    res = extract_job_gender(ent)\n",
    "    job_gender = res[0]\n",
    "    if job_gender == \"female\":\n",
    "        female_tp.append(ent)\n",
    "    elif job_gender == \"male\":\n",
    "        male_tp.append(ent)\n",
    "    elif job_gender == \"common\":\n",
    "        common_tp.append(ent)\n",
    "    else:\n",
    "        unknown_tp.append(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_fn, male_fn, common_fn, unknown_fn = [], [], [], []\n",
    "\n",
    "for ent in tqdm.tqdm(fn_list_balanced):\n",
    "    res = extract_job_gender(ent)\n",
    "    job_gender = res[0]\n",
    "    # print(job_gender)\n",
    "    if job_gender == \"female\":\n",
    "        female_fn.append(ent)\n",
    "    elif job_gender == \"male\":\n",
    "        male_fn.append(ent)\n",
    "    elif job_gender == \"common\":\n",
    "        common_fn.append(ent)\n",
    "    else:\n",
    "        unknown_fn.append(ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female recall: 0.802439024390244\n",
      "Male recall: 0.5867768595041323\n",
      "Comon recall: 0.873015873015873\n",
      "Unknown recall: 0.3125\n"
     ]
    }
   ],
   "source": [
    "female_recall = len(female_tp) / (len(female_tp) + len(female_fn)) if (len(female_tp) + len(female_fn)) > 0 else 0\n",
    "print(\"Female recall:\", female_recall)\n",
    "male_recall = len(male_tp) / (len(male_tp) + len(male_fn)) if (len(male_tp) + len(male_fn)) > 0 else 0\n",
    "print(\"Male recall:\", male_recall)\n",
    "common_recall = len(common_tp) / (len(common_tp) + len(common_fn)) if (len(common_tp) + len(common_fn)) > 0 else 0\n",
    "print(\"Comon recall:\", common_recall)\n",
    "unknown_recall = len(unknown_tp) / (len(unknown_tp) + len(unknown_fn)) if (len(unknown_tp) + len(unknown_fn)) > 0 else 0\n",
    "print(\"Unknown recall:\", unknown_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list_orig = read_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/results_of_evaluation/NER_JOB_class_results/orig_fn.txt\")\n",
    "tp_list_orig = read_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/results_of_evaluation/NER_JOB_class_results/orig_tp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_female_tp, orig_male_tp, orig_common_tp, orig_unknown_tp = [], [], [], []\n",
    "\n",
    "for ent in tqdm.tqdm(tp_list_orig):\n",
    "    res = extract_job_gender(ent)\n",
    "    job_gender = res[0]\n",
    "    # print(job_gender)\n",
    "    if job_gender == \"female\":\n",
    "        orig_female_tp.append(ent)\n",
    "    elif job_gender == \"male\":\n",
    "        orig_male_tp.append(ent)\n",
    "    elif job_gender == \"common\":\n",
    "        orig_common_tp.append(ent)\n",
    "    else:\n",
    "        orig_unknown_tp.append(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_female_fn, orig_male_fn, orig_common_fn, orig_unknown_fn = [], [], [], []\n",
    "\n",
    "for ent in tqdm.tqdm(fn_list_orig):\n",
    "\n",
    "    res = extract_job_gender(ent)\n",
    "    job_gender = res[0]\n",
    "    # print(job_gender)\n",
    "    if job_gender == \"female\":\n",
    "        orig_female_fn.append(ent)\n",
    "    elif job_gender == \"male\":\n",
    "        orig_male_fn.append(ent)\n",
    "    elif job_gender == \"common\":\n",
    "        orig_common_fn.append(ent)\n",
    "    else:\n",
    "        orig_unknown_fn.append(ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_male_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female recall: 0.6899766899766899\n",
      "Male recall: 0.6406995230524642\n",
      "Common recall: 0.8492063492063492\n",
      "Common recall: 0.2037037037037037\n"
     ]
    }
   ],
   "source": [
    "orig_female_recall = len(orig_female_tp) / (len(orig_female_tp) + len(orig_female_fn)) if (len(orig_female_tp) + len(orig_female_fn)) > 0 else 0\n",
    "print(\"Female recall:\", orig_female_recall)\n",
    "orig_male_recall = len(orig_male_tp) / (len(orig_male_tp) + len(orig_male_fn)) if (len(orig_male_tp) + len(orig_male_fn)) > 0 else 0\n",
    "print(\"Male recall:\", orig_male_recall)\n",
    "orig_common_recall = len(orig_common_tp) / (len(orig_common_tp) + len(orig_common_fn)) if (len(orig_common_tp) + len(orig_common_fn)) > 0 else 0\n",
    "print(\"Common recall:\", orig_common_recall)\n",
    "orig_unknown_recall = len(orig_unknown_tp) / (len(orig_unknown_tp) + len(orig_unknown_fn)) if (len(orig_unknown_tp) + len(orig_unknown_fn)) > 0 else 0\n",
    "print(\"Unknown recall:\", orig_unknown_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender distribution for JOB entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def extract_job_entities(directory):\n",
    "    pers_entities = {}\n",
    "    \n",
    "    ann_files = glob.glob(os.path.join(directory, \"*.ann\"))\n",
    "    print(ann_files)\n",
    "    \n",
    "    for ann_file in ann_files:\n",
    "        with open(ann_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) == 5:\n",
    "                    \n",
    "                    entity_type = parts[1]\n",
    "                    \n",
    "                    if entity_type == \"JOB\":\n",
    "                        entity_text = parts[4]\n",
    "                        if ann_file in pers_entities:\n",
    "                            pers_entities[ann_file].append(entity_text)\n",
    "                        else:\n",
    "                            pers_entities[ann_file] = [entity_text]\n",
    "    \n",
    "    return pers_entities\n",
    "\n",
    "def return_gendered_job_dict(pers_dict):\n",
    "    file_gender_dict = {\"male\": {}, \"female\": {}, \"common\": {}, \"unknown_gender\": {}}\n",
    "\n",
    "    total_pers_counter = 0\n",
    "    pers_list = []\n",
    "\n",
    "    for filename, values in tqdm.tqdm(pers_dict.items()):\n",
    "        filename = filename.replace(\".ann\", \".txt\")\n",
    "        \n",
    "        try:\n",
    "            for ent in values:\n",
    "                total_pers_counter += 1\n",
    "                pers_list.append(ent)\n",
    "\n",
    "                gender_value, lemma_word = extract_job_gender(ent)\n",
    "                \n",
    "                if filename not in file_gender_dict[gender_value]:\n",
    "                    file_gender_dict[gender_value][filename] = [(ent, lemma_word)]\n",
    "                else:\n",
    "                    file_gender_dict[gender_value][filename].append((ent, lemma_word))\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Issue with row: {row} - Error: {e}\")\n",
    "    return file_gender_dict, total_pers_counter, pers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender distribution of JOB entities for Original corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruk_orig_job_dict = extract_job_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/bruk\")\n",
    "bruk_orig_job_file_gender_dict, bruk_orig_job_total_counter, bruk_orig_job_list = return_gendered_job_dict(bruk_orig_job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 638\n",
      "================\n",
      "gender: male\n",
      "number of files for the gender: 122\n",
      "number of entities for the gender: 511\n",
      "The most popular entity: поет\n",
      "================\n",
      "================\n",
      "gender: female\n",
      "number of files for the gender: 23\n",
      "number of entities for the gender: 49\n",
      "The most popular entity: вчителька\n",
      "================\n",
      "================\n",
      "gender: common\n",
      "number of files for the gender: 24\n",
      "number of entities for the gender: 53\n",
      "The most popular entity: голова\n",
      "================\n",
      "================\n",
      "gender: unknown_gender\n",
      "number of files for the gender: 14\n",
      "number of entities for the gender: 25\n",
      "The most popular entity: наука\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "return_gender_stat(bruk_orig_job_total_counter, bruk_orig_job_file_gender_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_orig_job_dict = extract_job_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/ng\")\n",
    "ng_orig_job_file_gender_dict, ng_orig_job_total_counter, ng_orig_job_list = return_gendered_job_dict(ng_orig_job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 1344\n",
      "================\n",
      "gender: male\n",
      "number of files for the gender: 269\n",
      "number of entities for the gender: 1135\n",
      "The most popular entity: директор\n",
      "================\n",
      "================\n",
      "gender: female\n",
      "number of files for the gender: 16\n",
      "number of entities for the gender: 27\n",
      "The most popular entity: підприємиця\n",
      "================\n",
      "================\n",
      "gender: common\n",
      "number of files for the gender: 85\n",
      "number of entities for the gender: 170\n",
      "The most popular entity: голова\n",
      "================\n",
      "================\n",
      "gender: unknown_gender\n",
      "number of files for the gender: 9\n",
      "number of entities for the gender: 12\n",
      "The most popular entity: в\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "return_gender_stat(ng_orig_job_total_counter, ng_orig_job_file_gender_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender distribution of JOB entities for Filtered Swapped corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bruk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruk_job_dict = extract_job_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0-swapped/data/bruk\")\n",
    "bruk_swapped_job_file_gender_dict, bruk_job_total_counter, bruk_job_list = return_gendered_job_dict(bruk_job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_jobs_bruk_swapped = []\n",
    "for gender, val in bruk_swapped_job_file_gender_dict.items():\n",
    "    for filename, ents in val.items():\n",
    "        for pair_ent in ents:\n",
    "            lemma_jobs_bruk_swapped.append(pair_ent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/job_lists/bruk_job_list_in_swapped_df.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lemma_jobs_bruk_swapped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 481\n",
      "================\n",
      "gender: male\n",
      "number of files for the gender: 39\n",
      "number of entities for the gender: 67\n",
      "percentage: 0.1392931392931393\n",
      "The most popular entity: вчитель\n",
      "================\n",
      "================\n",
      "gender: female\n",
      "number of files for the gender: 107\n",
      "number of entities for the gender: 343\n",
      "percentage: 0.7130977130977131\n",
      "The most popular entity: журналістка\n",
      "================\n",
      "================\n",
      "gender: common\n",
      "number of files for the gender: 21\n",
      "number of entities for the gender: 33\n",
      "percentage: 0.06860706860706861\n",
      "The most popular entity: голова\n",
      "================\n",
      "================\n",
      "gender: unknown_gender\n",
      "number of files for the gender: 23\n",
      "number of entities for the gender: 38\n",
      "percentage: 0.079002079002079\n",
      "The most popular entity: наука\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "return_gender_stat(bruk_job_total_counter, bruk_swapped_job_file_gender_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_job_dict = extract_job_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0-swapped/data/ng\")\n",
    "ng_swapped_job_file_gender_dict, ng_job_total_counter, ng_job_list = return_gendered_job_dict(ng_job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_jobs_ng_swapped = []\n",
    "for gender, val in ng_swapped_job_file_gender_dict.items():\n",
    "    for filename, ents in val.items():\n",
    "        for pair_ent in ents:\n",
    "            lemma_jobs_ng_swapped.append(pair_ent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/job_lists/ng_job_list_in_swapped_df.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lemma_jobs_ng_swapped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 1248\n",
      "================\n",
      "gender: male\n",
      "number of files for the gender: 71\n",
      "number of entities for the gender: 114\n",
      "percentage: 0.09134615384615384\n",
      "The most popular entity: засновник\n",
      "================\n",
      "================\n",
      "gender: female\n",
      "number of files for the gender: 257\n",
      "number of entities for the gender: 972\n",
      "percentage: 0.7788461538461539\n",
      "The most popular entity: директорка\n",
      "================\n",
      "================\n",
      "gender: common\n",
      "number of files for the gender: 78\n",
      "number of entities for the gender: 135\n",
      "percentage: 0.10817307692307693\n",
      "The most popular entity: голова\n",
      "================\n",
      "================\n",
      "gender: unknown_gender\n",
      "number of files for the gender: 26\n",
      "number of entities for the gender: 27\n",
      "percentage: 0.021634615384615384\n",
      "The most popular entity: в\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "return_gender_stat(ng_job_total_counter, ng_swapped_job_file_gender_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 1733\n",
      "male: 182\n",
      "female: 1316\n",
      "common: 170\n",
      "unknown: 65\n"
     ]
    }
   ],
   "source": [
    "print(\"total:\", 483 + 1250)\n",
    "print(\"male:\", 67 + 115)\n",
    "print(\"female:\", 345 + 971)\n",
    "print(\"common:\", 35 + 135)\n",
    "print(\"unknown:\", 38 + 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pairs df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_filename(name):\n",
    "    \"\"\"Remove '_1.txt' suffix to align with original filename\"\"\"\n",
    "    return re.sub(r'-swapped(?=\\.txt$)', '', name)\n",
    "\n",
    "def flatten_all_gender_dicts(gender_dict):\n",
    "    \"\"\"Flatten a nested gender-based dict into a flat filename -> items dict\"\"\"\n",
    "    flat = {}\n",
    "    for gender in ['male', 'female', 'common']:\n",
    "        if gender in gender_dict:\n",
    "            for fname, items in gender_dict[gender].items():\n",
    "                flat[fname] = items\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs_df(aligned_pairs):\n",
    "    rows = []\n",
    "    for filename, entity_dict in aligned_pairs.items():\n",
    "        for tid, (orig_text, swapped_text) in entity_dict.items():\n",
    "            rows.append({\n",
    "                \"filename\": filename,\n",
    "                \"entity_id\": tid,\n",
    "                \"original\": orig_text,\n",
    "                \"swapped\": swapped_text\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_pairs = {}\n",
    "\n",
    "original_flat = flatten_all_gender_dicts(ng_orig_job_file_gender_dict)\n",
    "swapped_flat = flatten_all_gender_dicts(ng_swapped_job_file_gender_dict)\n",
    "\n",
    "for swapped_fname, swapped_ents in swapped_flat.items():\n",
    "    orig_fname = normalize_filename(swapped_fname)\n",
    "    if orig_fname in original_flat:\n",
    "        orig_ents = dict(original_flat[orig_fname])\n",
    "        swapped_ents_dict = dict(swapped_ents)\n",
    "        paired = {\n",
    "            tid: (orig_ents[tid], swapped_ents_dict[tid])\n",
    "            for tid in orig_ents\n",
    "            if tid in swapped_ents_dict\n",
    "        }\n",
    "        if paired:\n",
    "            aligned_pairs[orig_fname] = paired\n",
    "\n",
    "ng_df = create_pairs_df(aligned_pairs)\n",
    "ng_df.to_csv(\"ng_gender_pairs_from_swapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_pairs = {}\n",
    "\n",
    "original_flat = flatten_all_gender_dicts(bruk_orig_job_file_gender_dict)\n",
    "swapped_flat = flatten_all_gender_dicts(bruk_swapped_job_file_gender_dict)\n",
    "\n",
    "for swapped_fname, swapped_ents in swapped_flat.items():\n",
    "    orig_fname = normalize_filename(swapped_fname)\n",
    "    if orig_fname in original_flat:\n",
    "        orig_ents = dict(original_flat[orig_fname])\n",
    "        swapped_ents_dict = dict(swapped_ents)\n",
    "        paired = {\n",
    "            tid: (orig_ents[tid], swapped_ents_dict[tid])\n",
    "            for tid in orig_ents\n",
    "            if tid in swapped_ents_dict\n",
    "        }\n",
    "        if paired:\n",
    "            aligned_pairs[orig_fname] = paired\n",
    "\n",
    "bruk_df = create_pairs_df(aligned_pairs)\n",
    "bruk_df.to_csv(\"bruk_gender_pairs_from_swapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender distribution of PERS entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_names = pd.read_csv(\"/Users/linndfors/study/diploma/ner_for_fem/src/female_fname_freq_dict.csv\")\n",
    "male_names = pd.read_csv(\"/Users/linndfors/study/diploma/ner_for_fem/src/male_fname_freq_dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_names_list = female_names['name'].values\n",
    "male_names_list = male_names['name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = pd.read_csv('/Users/linndfors/study/diploma/dict_uk/out/dict_corp_lt.txt', delimiter=' ', header=None, names=['word', 'lemma', 'grammar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_sex(name):\n",
    "    try:\n",
    "        filtered_df = dict_df[(dict_df['lemma'] == name) & (dict_df['word'] == name)]\n",
    "        if not filtered_df.empty:\n",
    "            grammar_pers = filtered_df['grammar'].iloc[0]\n",
    "\n",
    "            if re.search(r'fname', grammar_pers):\n",
    "                if re.search(r'\\bf\\b', grammar_pers):\n",
    "                    return \"F\"\n",
    "                elif re.search(r'\\bm\\b', grammar_pers):\n",
    "                    return \"M\"\n",
    "                else:\n",
    "                    return \"U\"\n",
    "            elif re.search(r'lname', grammar_pers):\n",
    "                return \"U\"\n",
    "            else:\n",
    "                return \"U\"\n",
    "        else:\n",
    "            # print(\"No matches found for:\", name)\n",
    "            return \"U\"\n",
    "    except Exception as e:\n",
    "        # print(\"error\", e)\n",
    "        return \"U\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def extract_gender(entity):\n",
    "\n",
    "    pers_parts = entity.split(\" \")\n",
    "    for i in pers_parts:\n",
    "        if define_sex(i) == \"F\":\n",
    "            return \"female\", i\n",
    "        elif define_sex(i) == \"M\":\n",
    "            return \"male\", i\n",
    "                \n",
    "    doc = nlp(entity)\n",
    "    \n",
    "    words = {word.lemma for sentence in doc.sentences for word in sentence.words}\n",
    "    words.update(entity.split(\" \"))\n",
    "\n",
    "    for x in words:\n",
    "        if x in female_names_list:\n",
    "            return \"female\", x\n",
    "        if x in male_names_list:\n",
    "            return \"male\", x\n",
    "        \n",
    "    # print(\"unkown for:\", entity)\n",
    "    return \"unknown_gender\", entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pers_entities(directory):\n",
    "    pers_entities = {}\n",
    "    \n",
    "    ann_files = glob.glob(os.path.join(directory, \"*.ann\"))\n",
    "    print(ann_files)\n",
    "    \n",
    "    for ann_file in ann_files:\n",
    "        with open(ann_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) == 5:\n",
    "                    \n",
    "                    entity_type = parts[1]\n",
    "                    \n",
    "                    if entity_type == \"PERS\":\n",
    "                        entity_text = parts[4]\n",
    "                        if ann_file in pers_entities:\n",
    "                            pers_entities[ann_file].append(entity_text)\n",
    "                        else:\n",
    "                            pers_entities[ann_file] = [entity_text]\n",
    "    \n",
    "    return pers_entities\n",
    "\n",
    "def return_gendered_PERS_dict(pers_dict):\n",
    "    file_gender_dict = {\"male\": {}, \"female\": {}, \"unknown_gender\": {}}\n",
    "\n",
    "    total_pers_counter = 0\n",
    "    pers_list = []\n",
    "\n",
    "    for filename, values in tqdm.tqdm(pers_dict.items()):\n",
    "        filename = filename.replace(\".ann\", \".txt\")\n",
    "        \n",
    "        try:\n",
    "            for ent in values:\n",
    "                total_pers_counter += 1\n",
    "                pers_list.append(ent)\n",
    "                if len(ent.split(' ')) > 1:\n",
    "                    ent = ent.split(' ')[0]\n",
    "                gender_value, lemma_word = extract_gender(ent)\n",
    "                # print(gender_value, lemma_word)\n",
    "                \n",
    "                if filename not in file_gender_dict[gender_value]:\n",
    "                    file_gender_dict[gender_value][filename] = [(ent, lemma_word)]\n",
    "                else:\n",
    "                    file_gender_dict[gender_value][filename].append((ent, lemma_word))\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Issue with row: {row} - Error: {e}\")\n",
    "    return file_gender_dict, total_pers_counter, pers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender distribution of PERS entities for Original corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRUK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruk_orig_pers_dict = extract_job_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/bruk\")\n",
    "bruk_orig_file_gender_pers_dict, bruk_orig_total_pers_counter, bruk_orig_pers_list = return_gendered_job_dict(bruk_orig_pers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 326\n",
      "================\n",
      "gender: male\n",
      "number of files for the gender: 97\n",
      "number of entities for the gender: 141\n",
      "The most popular entity: Андрій\n",
      "================\n",
      "================\n",
      "gender: female\n",
      "number of files for the gender: 42\n",
      "number of entities for the gender: 51\n",
      "The most popular entity: Аліна\n",
      "================\n",
      "================\n",
      "gender: unknown_gender\n",
      "number of files for the gender: 118\n",
      "number of entities for the gender: 134\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "return_gender_stat(bruk_orig_total_pers_counter, bruk_orig_file_gender_pers_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_orig_pers_dict = extract_pers_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0/data/ng\")\n",
    "ng_orig_file_gender_pers_dict, ng_orig_total_pers_counter, ng_orig_pers_list = return_gendered_PERS_dict(ng_orig_pers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 1058\n",
      "================\n",
      "gender: male\n",
      "number of files for the gender: 374\n",
      "number of entities for the gender: 526\n",
      "The most popular entity: Сергій\n",
      "================\n",
      "================\n",
      "gender: female\n",
      "number of files for the gender: 140\n",
      "number of entities for the gender: 180\n",
      "The most popular entity: Олена\n",
      "================\n",
      "================\n",
      "gender: unknown_gender\n",
      "number of files for the gender: 192\n",
      "number of entities for the gender: 352\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "return_gender_stat(ng_orig_total_pers_counter, ng_orig_file_gender_pers_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender distribution of PERS entities for Filtered Swapped corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_pers_dict = extract_pers_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0-swapped_filtering/data/ng\")\n",
    "ng_file_gender_pers_dict, ng_total_pers_counter, ng_pers_list = return_gendered_PERS_dict(ng_pers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 1003\n",
      "================\n",
      "gender: male\n",
      "number of files for the gender: 80\n",
      "number of entities for the gender: 126\n",
      "percentage: 0.12562313060817548\n",
      "The most popular entity: Олександр\n",
      "================\n",
      "================\n",
      "gender: female\n",
      "number of files for the gender: 223\n",
      "number of entities for the gender: 604\n",
      "percentage: 0.6021934197407777\n",
      "The most popular entity: Олена\n",
      "================\n",
      "================\n",
      "gender: unknown_gender\n",
      "number of files for the gender: 139\n",
      "number of entities for the gender: 273\n",
      "percentage: 0.27218344965104685\n",
      "The most popular entity: Юлії\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "return_gender_stat(ng_total_pers_counter, ng_file_gender_pers_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bruk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruk_pers_dict = extract_pers_entities(\"/Users/linndfors/study/diploma/ner_for_fem/data/v2.0-swapped_filtering/data/bruk\")\n",
    "bruk_file_gender_pers_dict, bruk_total_pers_counter, bruk_pers_list = return_gendered_PERS_dict(bruk_pers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 279\n",
      "================\n",
      "gender: male\n",
      "number of files for the gender: 25\n",
      "number of entities for the gender: 30\n",
      "percentage: 0.10752688172043011\n",
      "The most popular entity: Василь\n",
      "================\n",
      "================\n",
      "gender: female\n",
      "number of files for the gender: 65\n",
      "number of entities for the gender: 126\n",
      "percentage: 0.45161290322580644\n",
      "The most popular entity: Олександра\n",
      "================\n",
      "================\n",
      "gender: unknown_gender\n",
      "number of files for the gender: 46\n",
      "number of entities for the gender: 123\n",
      "percentage: 0.44086021505376344\n",
      "The most popular entity: Т\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "return_gender_stat(bruk_total_pers_counter, bruk_file_gender_pers_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 1282\n",
      "male: 156\n",
      "female: 730\n",
      "unknown: 396\n"
     ]
    }
   ],
   "source": [
    "print(\"total:\", 1282)\n",
    "print(\"male:\", 126 + 30)\n",
    "print(\"female:\", 604 + 126)\n",
    "print(\"unknown:\", 123 + 273)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
